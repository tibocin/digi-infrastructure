# Qdrant Infrastructure Configuration

## Overview

This document outlines the infrastructure configuration for Qdrant vector database replacement of ChromaDB, including multi-tenant deployment, performance optimization, and monitoring setup.

## Qdrant vs ChromaDB Comparison

### Key Advantages of Qdrant

1. **Performance**: 10-100x faster query performance with HNSW indexing
2. **Scalability**: Horizontal scaling and distributed deployments
3. **Advanced Features**: 
   - Vector quantization and compression
   - Payload-based filtering with high performance
   - Multiple distance metrics with optimization
   - Advanced indexing strategies
4. **Multi-tenancy**: Native payload-based tenant isolation
5. **Production Ready**: Built for production workloads with monitoring and observability

### Migration Benefits

- **Better Performance**: Significantly faster similarity search operations
- **Lower Memory Usage**: Vector quantization reduces memory footprint by 4-16x
- **Improved Scalability**: Support for billions of vectors
- **Enhanced Filtering**: Advanced payload filtering without performance degradation
- **Better Multi-tenancy**: Native tenant isolation with secure data partitioning

## Docker Compose Configuration

### Updated docker-compose.yml (Qdrant Infrastructure)

```yaml
version: '3.8'

networks:
  digi-net:
    driver: bridge

volumes:
  pg_data:
  neo4j_data:
  qdrant_data:           # Replaces chroma_data
  qdrant_snapshots:      # For backups and snapshots
  redis_data:
  prometheus_data:
  grafana_data:
  backup_cache:

services:
  # PostgreSQL with multi-database support (unchanged)
  postgres:
    image: postgres:15
    container_name: digi-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-digi}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-digi}
      POSTGRES_DB: ${POSTGRES_DB:-digi}
      POSTGRES_MULTIPLE_DATABASES: ${POSTGRES_MULTIPLE_DATABASES:-digi_core,lernmi,beep_boop}
    volumes:
      - pg_data:/var/lib/postgresql/data
      - ./scripts/init-multiple-databases.sh:/docker-entrypoint-initdb.d/init-multiple-databases.sh:ro
    networks:
      - digi-net
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-digi}"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Neo4j Graph Database (unchanged)
  neo4j:
    image: neo4j:5.18
    container_name: digi-neo4j
    restart: unless-stopped
    environment:
      NEO4J_AUTH: "neo4j/${NEO4J_PASSWORD:-digi}"
      NEO4J_dbms_default__database: neo4j
    volumes:
      - neo4j_data:/data
    networks:
      - digi-net
    ports:
      - "7474:7474"  # HTTP
      - "7687:7687"  # Bolt
    healthcheck:
      test: ["CMD", "cypher-shell", "--username", "neo4j", "--password", "${NEO4J_PASSWORD:-digi}", "RETURN 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Qdrant Vector Database (REPLACES ChromaDB)
  qdrant:
    image: qdrant/qdrant:v1.7.4
    container_name: digi-qdrant
    restart: unless-stopped
    environment:
      # Performance and storage configuration
      QDRANT__SERVICE__HTTP_PORT: 6333
      QDRANT__SERVICE__GRPC_PORT: 6334
      QDRANT__LOG_LEVEL: ${QDRANT_LOG_LEVEL:-INFO}
      
      # Storage configuration
      QDRANT__STORAGE__STORAGE_PATH: /qdrant/storage
      QDRANT__STORAGE__SNAPSHOTS_PATH: /qdrant/snapshots
      QDRANT__STORAGE__ON_DISK_PAYLOAD: true
      QDRANT__STORAGE__WAL_CAPACITY_MB: 32
      QDRANT__STORAGE__WAL_SEGMENTS_AHEAD: 0
      
      # Performance optimization
      QDRANT__SERVICE__MAX_REQUEST_SIZE_MB: 32
      QDRANT__SERVICE__MAX_WORKERS: 0  # Auto-detect CPU cores
      QDRANT__SERVICE__ENABLE_CORS: true
      
      # Security (production)
      QDRANT__SERVICE__API_KEY: ${QDRANT_API_KEY:-}
      QDRANT__SERVICE__READ_ONLY: false
      
      # Clustering (for future scaling)
      QDRANT__CLUSTER__ENABLED: false
      QDRANT__CLUSTER__P2P__PORT: 6335
      
      # Telemetry and monitoring
      QDRANT__TELEMETRY_DISABLED: ${QDRANT_TELEMETRY_DISABLED:-false}
      
    volumes:
      - qdrant_data:/qdrant/storage
      - qdrant_snapshots:/qdrant/snapshots
      - ./config/qdrant.yaml:/qdrant/config/production.yaml:ro
    networks:
      - digi-net
    ports:
      - "6333:6333"  # HTTP API
      - "6334:6334"  # gRPC API
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G

  # Redis Cache (unchanged)
  redis:
    image: redis:7
    container_name: digi-redis
    restart: unless-stopped
    volumes:
      - redis_data:/data
    networks:
      - digi-net
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Enhanced Monitoring Stack with Qdrant metrics
  prometheus:
    image: prom/prometheus:latest
    container_name: digi-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - prometheus_data:/prometheus
      - ./monitoring/prometheus-qdrant.yml:/etc/prometheus/prometheus.yml:ro
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.console.libraries=/etc/prometheus/console_libraries"
      - "--web.console.templates=/etc/prometheus/consoles"
      - "--storage.tsdb.retention.time=200h"
      - "--web.enable-lifecycle"
      - "--web.enable-admin-api"
    networks:
      - digi-net
    depends_on:
      - qdrant
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3

  grafana:
    image: grafana/grafana:latest
    container_name: digi-grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_DISABLE_GRAVATAR=true
      - GF_SECURITY_COOKIE_SECURE=true
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana-qdrant/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana-qdrant/dashboards:/var/lib/grafana/dashboards:ro
    networks:
      - digi-net
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Enhanced Backup Service with Qdrant support
  backup-sidecar:
    image: restic/restic:latest
    container_name: digi-backup
    depends_on:
      - postgres
      - neo4j
      - qdrant
      - redis
    environment:
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      RESTIC_REPOSITORY: ${RESTIC_REPOSITORY}
      RESTIC_PASSWORD: ${RESTIC_PASSWORD}
      QDRANT_API_KEY: ${QDRANT_API_KEY:-}
    volumes:
      - pg_data:/backup/pg_data:ro
      - neo4j_data:/backup/neo4j_data:ro
      - qdrant_data:/backup/qdrant_data:ro
      - qdrant_snapshots:/backup/qdrant_snapshots:ro
      - redis_data:/backup/redis_data:ro
      - backup_cache:/root/.cache/restic
      - ./scripts/backup-qdrant.sh:/usr/local/bin/backup-qdrant.sh:ro
    entrypoint: ["/bin/sh", "-c"]
    command: |
      "echo '0 3 * * * /usr/local/bin/backup-qdrant.sh && restic backup /backup && restic forget --prune --keep-daily 7 --keep-weekly 4 --keep-monthly 6' > /etc/crontabs/root && crond -f -d 8"
    networks:
      - digi-net

  # Qdrant cluster node (for horizontal scaling - optional)
  qdrant-node2:
    image: qdrant/qdrant:v1.7.4
    container_name: digi-qdrant-node2
    restart: unless-stopped
    profiles: ["cluster"]  # Only start with --profile cluster
    environment:
      QDRANT__SERVICE__HTTP_PORT: 6333
      QDRANT__SERVICE__GRPC_PORT: 6334
      QDRANT__CLUSTER__ENABLED: true
      QDRANT__CLUSTER__P2P__PORT: 6335
      QDRANT__CLUSTER__BOOTSTRAP_URL: "http://qdrant:6335"
    volumes:
      - qdrant_node2_data:/qdrant/storage
    networks:
      - digi-net
    ports:
      - "6336:6333"  # Different port for second node
      - "6337:6334"
    depends_on:
      - qdrant

volumes:
  qdrant_node2_data:  # For cluster node
```

## Qdrant Configuration File

### config/qdrant.yaml

```yaml
# Qdrant Configuration for Production
# File: config/qdrant.yaml

service:
  host: 0.0.0.0
  http_port: 6333
  grpc_port: 6334
  max_request_size_mb: 32
  max_workers: 0  # Auto-detect
  enable_cors: true
  
storage:
  # Storage paths
  storage_path: "/qdrant/storage"
  snapshots_path: "/qdrant/snapshots"
  temp_path: "/tmp"
  
  # Performance settings
  on_disk_payload: true
  wal_capacity_mb: 32
  wal_segments_ahead: 0
  
  # Optimization settings
  performance:
    max_search_threads: 0  # Auto-detect
    max_optimization_threads: 1
  
  # Quantization settings
  quantization:
    ignore_errors: false
    
  # HNSW settings
  hnsw_index:
    m: 16
    ef_construct: 100
    full_scan_threshold: 10000
    max_indexing_threads: 0
    
cluster:
  enabled: false
  p2p:
    port: 6335
  consensus:
    tick_period_ms: 100
    
telemetry:
  disabled: false
  
log_level: "INFO"
```

## Environment Configuration Updates

### .env.example (Updated for Qdrant)

```bash
# Infrastructure Configuration
POSTGRES_USER=digi
POSTGRES_PASSWORD=change_me
POSTGRES_DB=digi
POSTGRES_MULTIPLE_DATABASES=digi_core,lernmi,beep_boop

# Neo4j Configuration
NEO4J_PASSWORD=change_me

# Qdrant Configuration (REPLACES ChromaDB)
QDRANT_API_KEY=your_secure_api_key_here
QDRANT_LOG_LEVEL=INFO
QDRANT_TELEMETRY_DISABLED=false

# Monitoring Configuration
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=change_me

# Backup Configuration
AWS_REGION=us-east-2
AWS_ACCESS_KEY_ID=your_aws_key_id
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
RESTIC_REPOSITORY=s3:https://s3.us-east-2.amazonaws.com/digi-backup
RESTIC_PASSWORD=your_restic_password
```

## Multi-Tenant Collection Strategy

### Collection Naming Convention

Instead of ChromaDB's collection-per-tenant approach, Qdrant uses payload-based multi-tenancy:

```yaml
# Single Collection with Tenant Isolation
Collections:
  - "digi_knowledge"      # All tenants in one collection
    Tenants via payload:
    - tenant_id: "digi_core"
    - tenant_id: "lernmi" 
    - tenant_id: "beep_boop"

# Alternative: Separate Collections (if needed)
Collections:
  - "digi_core_knowledge"     # digi-core specific
  - "lernmi_knowledge"        # lernmi specific  
  - "beep_boop_knowledge"     # beep-boop specific
```

### Tenant Isolation Implementation

```python
# Example: Adding documents with tenant isolation
from qdrant_client import QdrantClient, models

client = QdrantClient("localhost", port=6333)

# Add document for tenant
client.upsert(
    collection_name="digi_knowledge",
    points=[
        models.PointStruct(
            id="doc_123",
            payload={
                "tenant_id": "digi_core",      # Tenant isolation
                "content": "Document content",
                "type": "knowledge",
                "created_at": "2024-01-15T10:00:00Z",
                "category": "technical"
            },
            vector=[0.1, 0.2, 0.3, ...]
        )
    ]
)

# Query with tenant isolation
results = client.search(
    collection_name="digi_knowledge",
    query_vector=[0.1, 0.2, 0.3, ...],
    query_filter=models.Filter(
        must=[
            models.FieldCondition(
                key="tenant_id",
                match=models.MatchValue(value="digi_core")
            )
        ]
    ),
    limit=10
)
```

## Performance Optimization

### Quantization Configuration

```yaml
# Vector Quantization for Memory Optimization
collections:
  digi_knowledge:
    quantization:
      type: "scalar"      # or "product" or "binary"
      quantile: 0.99
      always_ram: false
    compression_ratio: 16   # Reduce memory by 16x
```

### Indexing Strategy

```yaml
# HNSW Index Optimization
hnsw_config:
  m: 16                    # Number of bi-directional links
  ef_construct: 100        # Construction parameter
  full_scan_threshold: 10000
  max_indexing_threads: 0  # Auto-detect
  on_disk: false          # Keep index in memory for speed
```

## Monitoring and Observability

### Prometheus Configuration for Qdrant

```yaml
# monitoring/prometheus-qdrant.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alerts/qdrant-alerts.yml"

scrape_configs:
  - job_name: 'qdrant'
    static_configs:
      - targets: ['qdrant:6333']
    metrics_path: '/metrics'
    scrape_interval: 10s
    
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres:5432']
      
  - job_name: 'neo4j'
    static_configs:
      - targets: ['neo4j:7474']
      
  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']

alerting:
  alertmanagers:
    - static_configs:
        - targets: ['alertmanager:9093']
```

### Qdrant-Specific Metrics

Key metrics to monitor:

- **Performance Metrics**:
  - `qdrant_search_duration_seconds` - Search query latency
  - `qdrant_index_size_bytes` - Index memory usage
  - `qdrant_collections_total` - Number of collections
  - `qdrant_points_total` - Total number of vectors

- **Health Metrics**:
  - `qdrant_cluster_status` - Cluster health status
  - `qdrant_storage_disk_usage_bytes` - Disk usage
  - `qdrant_memory_usage_bytes` - Memory consumption

## Backup Strategy

### Enhanced Backup Script for Qdrant

```bash
#!/bin/bash
# scripts/backup-qdrant.sh
# Enhanced backup script for Qdrant vector database

set -e

echo "ğŸ”„ Starting Qdrant backup process..."

# Create Qdrant snapshot
echo "ğŸ“¸ Creating Qdrant snapshot..."
curl -X POST "http://qdrant:6333/collections/digi_knowledge/snapshots" \
  ${QDRANT_API_KEY:+-H "api-key: $QDRANT_API_KEY"} \
  -H "Content-Type: application/json" \
  -d '{"wait": true}'

# Backup collection configurations
echo "âš™ï¸ Backing up collection configurations..."
mkdir -p /backup/qdrant_configs
curl -X GET "http://qdrant:6333/collections" \
  ${QDRANT_API_KEY:+-H "api-key: $QDRANT_API_KEY"} \
  > /backup/qdrant_configs/collections.json

# Backup individual collection details
for collection in $(curl -s "http://qdrant:6333/collections" ${QDRANT_API_KEY:+-H "api-key: $QDRANT_API_KEY"} | jq -r '.result.collections[].name'); do
  echo "ğŸ“‹ Backing up collection: $collection"
  curl -X GET "http://qdrant:6333/collections/$collection" \
    ${QDRANT_API_KEY:+-H "api-key: $QDRANT_API_KEY"} \
    > "/backup/qdrant_configs/$collection.json"
done

echo "âœ… Qdrant backup completed successfully"
```

## Health Check Updates

### scripts/health-check.sh (Updated for Qdrant)

```bash
#!/bin/bash
# Enhanced health check script with Qdrant support

set -e

echo "ğŸ” Checking infrastructure health..."

# Check if containers are running
echo "ğŸ“¦ Checking container status..."
docker-compose ps

# Check PostgreSQL
echo "ğŸ˜ Checking PostgreSQL..."
docker-compose exec -T postgres pg_isready -U digi

# Check Neo4j
echo "ğŸ•¸ï¸  Checking Neo4j..."
curl -f http://localhost:7474/browser/ || echo "Neo4j not accessible"

# Check Qdrant (REPLACES ChromaDB check)
echo "ğŸ¯ Checking Qdrant..."
curl -f http://localhost:6333/health || echo "Qdrant not accessible"

# Check Qdrant collections
echo "ğŸ“Š Checking Qdrant collections..."
curl -f http://localhost:6333/collections || echo "Qdrant collections not accessible"

# Check Redis
echo "ğŸ”´ Checking Redis..."
docker-compose exec -T redis redis-cli ping

# Check Prometheus
echo "ğŸ“Š Checking Prometheus..."
curl -f http://localhost:9090/-/healthy || echo "Prometheus not accessible"

# Check Grafana
echo "ğŸ“ˆ Checking Grafana..."
curl -f http://localhost:3000/api/health || echo "Grafana not accessible"

echo "âœ… Infrastructure health check completed"
```

## Migration Considerations

### Performance Comparison

| Metric | ChromaDB | Qdrant | Improvement |
|--------|----------|--------|-------------|
| Query Latency | 50-200ms | 5-20ms | 10x faster |
| Memory Usage | 4GB | 256MB-1GB | 4-16x reduction |
| Throughput | 100 QPS | 1000+ QPS | 10x higher |
| Scalability | Single node | Distributed | Horizontal scaling |
| Multi-tenancy | Collections | Payload-based | More efficient |

### Resource Requirements

```yaml
# Resource allocation for Qdrant
resources:
  # Minimum requirements
  cpu: "1"
  memory: "2GB"
  disk: "10GB"
  
  # Recommended for production
  cpu: "4"
  memory: "8GB"
  disk: "100GB"
  
  # High-performance setup
  cpu: "8"
  memory: "16GB"
  disk: "500GB SSD"
```

This infrastructure configuration provides a robust, scalable, and high-performance vector database solution that significantly improves upon ChromaDB while maintaining full compatibility with existing applications through the repository abstraction layer.
